#调查基于网格的导航：身体残疾的影响。
**摘要    **对于那些发现传统输入设备（如键盘和鼠标）难以使用的人来说，免提语音技术可能是一种有用的替代方法。已经研究了各种基于语音的导航技术，其中有几种可用于商业软件应用。在这些替代方案中，基于网格的导航已经证明了其潜力和局限性。在本文中，我们讨论了一项实证研究，评估了两种增强功能对基于网格的导航的功效：放大和微调。放大功能在选定区域变得足够小时放大，使得更容易看到目标和光标。微调功能允许用户将光标移动短距离以将光标定位在目标上。这项研究涉及一组身体残疾参与者，一组年龄相当的非残疾参与者组，以及第三组参与者，其中包括无残疾的年轻人。结果证实，放大和微调都显着改善了参与者在选择目标时的表现，尤其是小目标。提供所提议的增强中的一项或两项，大大减少了由于残疾和年龄造成的性能差距。结果将为基于语音的目标选择机制的设计提供信息，使用户可以更快地选择目标，同时减少错误。

##1.引言
操作系统（例如Windows Vista）或商业产品（例如，Dragon Naturally Speaking）内的自动语音识别（ASR）支持用于各种任务的基于语音的命令，例如与桌面应用程序交互并浏览网页[Vista;龙]。对于大众来说，ASR在与计算机或计算机相关设备（如车载导航系统）交互时提供了一种替代方案[Kawaguchi et al。 2001; Huggins-Daines等人。 2006年]。对于身体障碍妨碍使用传统输入设备（例如键盘和鼠标）的个人而言，ASR是一种有用的，价格合理的自然输入解决方案，易于学习使用[Sears et al。 2007]。随着年龄的增长，ASR也可能被证明是一种有价值的选择。例如，由于年龄相关的感官，运动或认知技能的下降，老年人有时会遇到使用传统输入设备的重大挑战[Worden et al。 1997; Czaja和Lee 2007]。

当使用计算机时，两类任务占绝大多数用户活动：文本生成和导航[Oviatt 1997]。以前的研究已经证实语音识别对于文本生成任务非常有效[Feng and Sears 2004]，但是空间导航任务，例如在桌面上选择图标，在网页上选择链接或图像，或者在文本文档中的单词[Karimullah et al。 2003;赖和Yankelovich 2007]。

综合使用指向设备和语音识别的多模式解决方案似乎对各种场景都很有前景[Cohen et al。 2004年]。例如，语音可用于生成空间导航的文本和指针设备[Oviatt 2007]。然而，这种解决方案对于一些身体有缺陷的用户来说可能是不可行的，对于这些用户来说，免提语音解决方案可能更有效[Feng and Sears 2004]。不幸的是，目前的基于语音的光标控制解决方案往往无法满足用户的期望[Oviatt 2007]。 ASR被残疾人广泛采用，需要更有效的基于语音的光标控制解决方案。 ASR作为个体年龄的潜在益处不太明确，需要进一步研究。

资源已投入到这个领域，寻求更好的光标控制机制[Sears et al。 2003;童和王2009]。与其他基于语音的光标控制解决方案相比，基于网格的解决方案已经引起较少关注，并且已经被忽略。基于网格的解决方案最初是为盲人用户开发的[Kamel and Landay 1999]，并且随后在没有视觉障碍的用户环境中进行了研究[Dai et al。 2005]。基于网格的导航提供了一种灵活可靠的替代方案，允许用户通过“向下钻取”到较小的网格来选择目标，直到光标位于期望的位置。然而，最近一项在实际环境中调查基于语音的交互的实地研究发现，基于网格的导航被认为是耗时的[Hu et al。 2009年]。

为了提高基于网格的解决方案的功效并满足上肢身体残疾的用户的需求，我们提出并评估了两种基于网格的导航：放大和微调。整合了两种增强的原型，并进行了实证研究以评估增强的功效。三组人参加了这项研究。第一组包括身体残疾的参与者。第二组是年龄相匹配的非残疾参与者组，第三组包括没有残疾的年轻人。 Zhu等人报道了从青年人收集的数据的初步分析。 [2009]。本文对全部三个参与群体的表现进行了全面分析。结果证实，微调和放大对于所有三组在性能和满意度方面均提供了显着的益处。但是，参与者群体的福利待遇各不相同。还讨论了未来研究的意义和方向。

##2.相关研究
正如刚刚讨论的那样，有效的基于语音的光标控制可能对多个用户群体有益，但最明显的受益者将是具有妨碍他们使用传统输入机制的身体障碍的个体。有了这个动机，我们简要总结了涉及身体障碍的用户的相关研究。我们还总结了以前关于基于语音的光标控制的研究，包括一些涉及基于网格的解决方案的研究。

###2.1身体有缺陷的用户
患有上肢身体障碍的人可能会遇到使用传统输入设备（如键盘和鼠标）的困难[Sears et al。 2007]。有许多疾病和情况会影响手部和手臂运动功能，如高水平脊髓损伤（SCI），肌萎缩侧索硬化（ALS）和中风[Sears et al。 2007]。多项研究报告说，与没有身体障碍的人相比，上肢身体障碍的人在完成打字和导航任务时花费更多时间并犯更多错误[Trewin 1996; Trewin and Pain 1999; Hwang 2002; Wobbrock和Gajos 2008]。另外的研究表明，身体障碍的人在完成基本的基于计算机的任务时会经历认知工作量的增加[Koester和Levine 1994]。

虽然广泛的研究已经研究了诸如电生理学和头部控制解决方案等替代性相互作用解决方案，但现有解决方案留下了很大改进空间[Mason et al。 2000; LoPresti和Brienza 2004]。常见的问题包括错误率高，成本高和失败。与其他替代方案相比，基于语音的解决方案相对成熟，成本低，且相当容易学习。

###2.2基于语音的光标控制
许多研究项目都调查了使用语音识别来与计算机进行交互。在识别速度和准确性方面取得了重大进展;在受控环境下准确度高达98％[Halverson et al。 1999; Karimullah等人2003]。

然而，免提语音系统必须同时支持听写和光标控制[Oviatt 1997]，并且多年来一直讨论使用语音处理空间任务的困难[Oviatt 2007]。

主要有两类基于语音的光标控制解决方案：基于方向和目标的解决方案。基于语音的光标控制解决方案也可以通过它们产生的光标移动类型来表征：分散或连续[Dai et al。 2004年]。例如，使用离散的基于方向的导航，用户指定移动方向和距离，例如“移动左三个单词”，并且光标立即跳到新位置。距离可以用英寸，厘米，单词或其他适合情况的单位来指定[Dai et al。 2004;龙]。在某些情况下，假定默认距离，例如一个字或一行。

对于连续的基于方向的解决方案[Sears et al。 2002]中，用户首先发出一个启动运动的命令（例如“向左移动”）。作为响应，光标在指定方向上平稳移动，直到被另一个命令（例如，“停止”）停止为止。不幸的是，据报这种解决方案既缓慢又容易出错[Karimullah and Sears 2002]。研究人员已经研究了各种机制来改进连续的基于方向的光束控制解决方案，包括允许用户控制光标的速度[Karimullah et al。 2003]，使用非语音声音[Igarashi和Hughes 2001; Bilmes等人2005; Harada等人2008; Mahmud等人2007]，预测性和幽灵游标[Karimullah and Sears 2002; Mihara等人2005]，并自动计算识别延迟[Tong and Wang 2009]。尽管一些增强功能的确提高了性能，但由此产生的技术仍然相对较慢并且容易出错，并且仍然存在重大挑战。例如，参与者在使用非语言发声来控制光标时报告了一些疲劳[Mihara et al。 2005]。虽然基于方向的解决方案允许用户控制移动方向和距离，但这些解决方案的功效受光标和目标的相对位置的影响。更重要的是，选择小目标仍然是一个挑战。

基于目标的光标控制利用上下文信息，允许用户通过指定所需对象的名称来选择目标。例如，“选择星期五”可以将光标移动到文本文档[Vista]中的单词“星期五”。一些研究集中在使语音导航技术更加有效，并强调文本文档中的导航[Feng and Sears 2004; Sears等人。 2003]。通过适当的增强，基于目标的导航在文本文件中被证明是有效的，但是当目标没有明确标记时它将如何运作还不太清楚[Karimullah and Sears 2002]。虽然这种方法可能更加自然和直接，但只有当所需对象具有已知名称时才起作用。随着接口变得更加复杂，目标数量将增加，许多目标可能没有清晰可见的标签，并且多个目标可能会共享同名，使现有的基于目标的技术效果较差。
基于网格的技术被提议作为选择没有上下文信息的对象的方式，因此在很多方面它应该与基于方向的导航进行比较。与基于方向的导航导致离散的光标移动一样，基于网格的解决方案会使光标跳到屏幕上的其他位置。但是，与基于方向的导航不同，可以同时在两个方向移动光标。使用这种技术，用户使用网格递归地向下钻取，直到光标放置在期望的对象上。该技术源于一种基于网格的绘图工具，该工具是为盲人使用而开发的[Kamel and Landay 1999; 2000; 2002]。最初的解决方案采用了3x3网格，展示了基于网格的语音光标控制的潜力。 Dai et al。 [2004]以这些结果为基础，让参与者使用两个替代方案完成目标选择任务：传统的解决方案，在网格中间有一个单一的光标，另一种方法是将光标放置在九个单元中的每一个的中心网格。结果表明，九光标解决方案速度更快，但导致更多的错误，建议单光标解决方案是未来勘探的更好选择。迄今为止，基于网格的方法在目标相当大时（例如桌面图标）显示出潜力，但由于目标较小（例如，文字，菜单图标，字母），因此它变得很麻烦。当目标足够小时，基于网格的导航会变得缓慢且容易出错。一些基于商业语音的解决方案（如Windows Vista或Dragon Natural Speaking中内置的解决方案）提供了基于网格导航的变体（例如，在Windows Vista中，基于网格的导航可通过MouseGrid命令获得）。

与基于目标的技术不同，基于网格的解决方案不要求将名称附加到每个对象，并且允许将光标定位在屏幕上的任何位置（例如屏幕上的空白区域）。基于网格的方法的有效性取决于光标，目标和网格本身的相对位置。如果一个目标位于网格中一个单元的中心附近，那么用户可以很容易地选择它，但是使用基于网格的方法选择小目标往往是有问题的。当目标很小时，用户可能需要发出五个或更多的命令，集中在屏幕的连续较小的部分，每个命令，使得确定目标和网格的相对位置有点困难[Dai et al人。 2004年]。同时，网格线和可能在网格单元内显示的数字可能会变得分散注意力，使得难以看到目标。

迄今为止，还没有进行过实证研究来评估基于网格的解决方案在身体残疾个人使用时的功效。为了弥补这一差距以及现有基于网格的解决方案所记录的挑战，我们提出了两种基于网格导航的改进方案，并对三组用户进行了实证评估：身体残疾的成年人，年龄匹配的无残疾成年人组和无残疾年轻人。放大倍数和微调增强都旨在提高目标选择的效率，特别是当目标很小时。放大使得查看小目标和判断光标和目标的相对位置变得更加容易，而微调允许用户对光标位置进行微调，从而确保光标直接位于目标上。


##参考文献
BILMES, J. A., LI, X., MALKIN, J., KILANSKI, K., WRIGHT, R., KIRCHHOFF, K., SUBRAMANYA, A., HARADA, S., LANDAY, J. A., DOWDEN, P., AND CHIZECK, H. 2005. The vocal joystick: A voice-based human-computer interface for individuals with motor impairments. In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing.CHARNESS, N. AND HOLLEY, P. 2001. Minimizing computer performance deficits via input de- vices and training. Workshop on Aging and Disabilities in the Information Age. John Hopkins University, Baltimore, MD.CHIN, C., BARRETO, A., CREMADES, G., AND ADJOUADI, M. 2007. Performance analysis of an integrated eye gaze tracking/electromyogram cursor control system. In Proceedings of the ASSETS. 233–234.

COHEN, M. H., GIANGOLA, J. P., AND BALOGH, J. 2004. Voice User Interface Design. Addison Wesley Longman Publishing Co., Inc., Redwood City, CA.CZAJA, S. AND LEE, C. C. 2007. Information technologies and older adults. In The Human- Computer Interaction Handbook: Fundamentals, Evolving Technologies, and Emerging Appli- cations, J. A. Jacko and A. Sears, Eds., L. Erlbaum Associates, Hillsdale, NJ, 777–792.DAI, L., GOLDMAN, R., SEARS, A., AND LOZIER, J. 2005. Speech-based cursor control using grids: Modeling performance and comparisons with other solutions. Behav. Inform. Techn. 24, 219–230.DRAGONTM NATURAL SPEAKING. http://www.nuance.com/naturallyspeaking/products/default.asp.EUROPA POPULATION PROJECTIONS. http://europa.eu/rapid/pressReleasesAction.do?reference=STAT/08/ 119&format=HTML&aged=0&language=EN&guiLanguage=en, 2009, 2008–2060.FENG, J. AND SEARS, A. 2004. Using confidence scores to improve hands-free speech based navi- gation in continuous dictation systems. ACM Trans. Comput.-Hum. Interact. 11, 4, 329–356.HALVERSON, C., HORN, D., KARAT, C., AND KARAT, J. 1999. The beauty of errors: Patterns of error correction in desktop speech systems. In Proceedings of the INTERACT. 1–9.HARADA, S., LANDAY, J. A., MALKIN, J., LI, X., AND BILMES, J. A. 2008. The vocal joystick: Evaluation of voice-based cursor control techniques for assistive technology. Disab. Rehab. Assist. Techn. 3, 1, 22–34.HU, R., ZHU, S., FENG, J., AND SEARS, A. 2009. Evolving requirements for speech applications: Lessons learned from a field study. Tech. paper. Author supply access.HUGGINS-DAINES, D., KUMAR, M., CHAN, A., BLACK, A., RAVISHANKAR, M., AND RUDNICKY, A. 2006. POCKETSPHINX: A free, real-time continous speech recognition system for hand-held devices. In Proceedings of the ICASSP. 185–188.HWANG, F. 2002. A study of cursor trajectories of motion-impaired users. In Proceedings of the Extended Abstracts on Human Factors in Computing Systems. 842–843.IGARASHI, T. AND HUGHES, J. 2001. Voice as sound: Using non-verbal voice input for interactive control. In Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology. ACM Press, New York, NY, 155–156.KAMEL, H. AND LANDAY, J. 1999. The integrated communication 2 draw (IC2D): A drawing pro- gram for the visually impaired. In Proceedings of the CHI. 345–352.KAMEL, H. AND LANDAY, J. 2000. A study of blind drawing practice: Creating graphical informa- tion without the visual channel. In Proceedings of the ASSETS. 34–41.KAMEL, H. AND LANDAY, J. 2002. Sketching images eyes-free: A grid-based dynamic drawing tool for the blind. In Proceedings of the ASSETS. 33–40.KARAT, C., VERGO, J., AND NAHAMOO, D. 2003. Conversational interface technologies. In J. Jacko, A. Sears, Eds., The Human-Computer Interaction Handbook, LEA: NJ, 169–186.KARIMULLAH, A. S. AND SEARS, A. 2002. Speech-based cursor control. In Proceedings of the ASSETS. 178–185.KARIMULLAH, A., SEARS, A., LIN, M., AND GOLDMAN, R. 2003. Speech-based cursor control: Understanding the effects of variable cursor speed on target selection. In Proceedings of the HCII. 681–685.KAWAGUCHI, N., MATSUBARA, S., TAKEDA, K., AND ITAKURA, F. 2001. Multimedia data collec- tion of in-car speech communication. In Proceedings of the 7th European Conference on Speech Communication and Technology (Eurospeech’01). 2027–2030.KLINE, D. W. AND SCHIEBER, F. J. 1985. Vision and aging. In J. E. Birren, K. W. Schaie, Eds., Handbook of the Psychology and Aging, Van Nostrand Reinhold, New York, 296–331.KOESTER, H. H. AND LEVINE, S. P. 1994. Validation of a keystroke-level model for a text en- try system used by people with disabilities. In Proceedings of the ASSETS. ACM, New York, 115–122.LAI, J. AND YANKELOVICH, N. 2007. Conversational speech interfaces. In The Human-Computer Interaction Handbook: Fundamentals, Evolving Technologies, and Emerging Applications, J. A. Jacko, A. Sears, Eds., L. Erlbaum Associates, Hillsdale, NJ, 698–713.LOPRESTI, E. AND BRIENZA, D. 2004. Adaptive software for head-operated computer controls. IEEE Trans. Neur. Syst. Rehab. Engin. 12, 1, 102–111.

MAHMUD, M., SPORKA, A. J., KURNIAWAN, S. H., AND SLAVIK, P. A. 2007. Comparative longitu- dinal study of non-verbal mouse pointer. In Proceedings of the INTERACT. 489–502.MASON, S. G., BOZORGZADEH, Z., AND BIRCH, G. E. 2000. The LG-ASD brain computer in- terface: On-line identification of imagined finger flexions in subjects with spinal cord injuries. In Proceedings of the ASSETS. ACM, New York, 109–113.MIHARA, Y., SHIBAYAMA, E., AND TAKAHASHI, S. 2005. The migratory cursor: Accurate speech- based cursor movement by moving multiple ghost cursors using non-verbal vocalizations. In Proceedings of the ASSETS. 76–83.MORRELL, R. W. AND ECHT, C. V. 1996. Instructional design for older computer users: The in- fluence of cognitive factors. In W. A. Rogers, A. D. Fisk, and N. Walker Eds., Aging and Skilled Performance: Advances in Theory and Application. Lawrence Erlbaum Associates, Mahwah, NJ, 241–265.NATIONAL CENTER FOR HEALTH STATISTICS. http://www.cdc.gov/nchs/.OVIATT, S. L. 1997. Multimodal interactive maps: Designing for human performance. Hum.-Comput. Interact. 12, 93–129.OVIATT, S. L. 2007. Multimodal interfaces. In The Human-Computer Interaction Handbook: Fun-damentals, Evolving Technologies, and Emerging Applications, J. A. Jacko, A. Sears, Eds., L.Erlbaum Associates, Hillsdale, NJ, 413–432.PARK, D. C. 1992. Applied cognitive aging research. In F. I. M. Crail, T. A. Salthouse Eds., TheHandbook of Aging and Cognition. Lawrence Erlbaum Associates, Mahwah, NJ, 449–494. SEARS, A., LIN, M., AND KARIMULLAH, A. 2002. Speech-based cursor control: Understanding the effects of target size, cursor speed, and command selection. Univ. Access Inform. Soc. 2, 1, 30–43. SEARS, A., YOUNG, M., AND FENG J. 2007. Physical disabilities and computing technologies: An analysis of impairments. In The Human-Computer Interaction Handbook: Fundamentals, Evolv- ing Technologies, and Emerging Applications, J. A. Jacko, A. Sears, Eds., L. Erlbaum Associates,Hillsdale, NJ, 829–852.SEARS, A., FENG, J., OSEITUTU, K., AND KARAT, C. 2003. Hands-free, speech-based naviga-tion during dictation: Difficulties, consequences, and solutions. Hum.-Comput. Interact. 18, 3,229–257.SMITH, N. W., SHARIT, J., AND CZAJA, S. J. 1999. Aging, motor control, and performance ofcomputer mouse tasks. Hum. Fact. 41, 3, 389–396.TONG, Q. AND WANG, Z. 2009. Compensate the speech recognition delays for accurate speech-based cursor position control. In Proceedings of the 13th International Conference on Human-Computer Interaction. Part II, Interaction Methods and Techniques, 752–760.TREWIN, S., KEATES, S., AND MOFFATT, K. 2006. Developing steady clicks: A method of cursor assistance for people with motor impairments. In Proceedings of the ASSETS. ACM Press, 26–33. WALKER, N., MILLIANS, J., AND WORDEN, A. 1996. Mouse accelerations and performance of older computer users. In Proceedings of the Human Factors and Ergonomics Society 40th AnnualMeeting. 151–154.TREWIN, S. 1996. A study of input device manipulation difficulties. In Proceedings of the ASSETS.ACM, New York, 15–22.TREWIN, S. AND PAIN, H. 1999. Keyboard and mouse errors due to motor disabilities. Int. J. Hum.-Comput. Stud. 50, 109–144.VISTATM SPEECH RECOGNITION. http://en.wikipedia.org/wiki/Windows Speech Recognition. WOBBROCK, J. AND GAJOS, K. 2008. Goal crossing with mice and trackballs for people with motorimpairments: Performance, submovements, and design directions. ACM Trans. Access. Comput.1, 1, 1–37.WORDEN, A., WALKER, N., BHARAT, K., AND HUDSON, S. 1997. Making computers easier forolder adults to use: Area cursors and sticky icons. In Proceedings of the SIGCHI. 266–271.ZHU, S., MA, Y., FENG, J., AND SEARS, A. 2009. Speech-based navigation: Improve grid- based solutions. In Proceedings of the 12th IFIP Conference on Human-Computer Interaction(INTERACT).
