# 基于语音的光标控制

**摘要    **语音识别对于无法正常使用传统输入设备的残疾人士来说是一个强大的工具。如今最先进的语音识别系统通常都提供了数据录入和光标控制的机制，但研究人员还在继续研究改善交互效率的方法。有许多研究人员正在研究改进底层算法使语音识别尽可能的提高识别准确度，而另一些研究人员则侧重于解决用户使用以听写为导向的应用程序所遇到的困难，但很少有研究人员研究基于语音的光标控制的问题。在本文中，我们描述了一项研究，该研究调查了标准语音游标控制机制的两种变体的功效。一个使用标准鼠标光标，而第二个提供预测光标，旨在帮助用户补偿通常与语音识别相关的延迟。正如预期的那样，更大的目标和更短的距离导致更短的目标选择时间，而更大的目标也导致更少的错误。尽管标准游标和预测游标之间没有差异，但与口语输入相关的延迟，光标移动的速度以及可以可靠选择的目标的最小尺寸之间的关系出现了，可以指导应用类似的语音基于光标的控制机制以及未来的研究。

**关键词    **语音识别，导航，鼠标光标，预测光标

## 简介

用户使用基于语音识别的听写系统可以允许用户通过对计算机说话来生成各种文本文档，包括电子邮件，备忘录和论文。身体的残疾会妨碍人们使用传统输入设备（如键盘和鼠标），因此，此类系统对于身体残疾的人而言是有价值的工具。类似地，当用户在特定环境或任务下，忙碌的使用传统的输入设备，这时候加入语音识别非常有用的。

当用户使用加入了语音识别图形用户界面的计算机，为了能够有效地控制计算机的所有功能，必须能够输入数据并操作光标，就像使用键盘和鼠标一样。尽管最先进的语音识别系统支持这两种活动，但所产生的交互速度通常比用键盘和鼠标实现的速度慢。一种有效的基于语音的光标控制机制，能够将光标定位在屏幕的任何位置，并启动点击，双击或拖动操作，对于需要与计算机进行交互的任何个人而言都是一种有价值的工具，但这种光标控制机制不能使用传统的指点设备。

## 基于语音的光标控制

基于目标或方向的导航，这两种基本方法已被用于基于语音的光标控制。对于基于目标的导航，用户识别期望的目的地（即目标）并发出适当的命令。只要用户知道所需目标的名称，他们就可以直接导航到屏幕的文字，图标，菜单或区域。不幸的是，随着可能的目标数量的增加，基于目标的导航变得更加容易出错。用户可能会发现记住目标名称更加困难，多个目标可能具有相同的名称（例如，一次可能在屏幕上显示三个“星期五”这个单词），并且词汇增加使识别错误变得更常见。基于目标的导航的示例包括：

* “选择星期五”，在文档中突出显示单词“星期五”
* 以及“移动鼠标至左上方”，将光标置于屏幕左上区域的中间位置

基于方向的导航会导致离散或连续移动。对于不连续的基于方向的导航，用户指定方向和距离（例如，以英寸，厘米，字母，单词）：“左移三个单词”将导致光标向左跳三个单词。对于连续的基于方向的导航，用户指定方向：“向左移动”使光标开始向左缓慢移动，直到发出“停止”命令。

我们的目标是提供基于语音的光标控制，有助于完全控制所有应用。当每个可能的目标都有一个名称，当用户记住所有这些名称，并且系统可以可靠地区分名称时，基于目标的导航可能会有效。在为用户提供对大量应用程序的完全控制时，标准的基于目标的导航不太可能证明是有效的。虽然屏幕区域可以用作目标，但标准的高分辨率显示器与通常用于细分屏幕的3x3网格相结合表明，这种方法不太可能有效。另外可以使用使用离散运动的基于方向的导航，但是最近的研究表明用户在基于面向口授的应用的情况下使用离散的基于方向的导航是非常困难的，其中运动基于字符，单词或者文字[^13]。尽管应该探索使用标准单位进行距离（例如，英寸或厘米）的离散的基于方向的导航，但这不是当前研究的焦点。相反，我们专注于持续的基于方向的导航。

## 相关研究

纠正识别错误的过程在过去的十年中受到了很大的关注。最近的一些研究证实，纠正这些错误占用户时间的很大一部分[^7,9,13]。更重要的是，最近的一项研究[^13]得出结论，用户花费了三分之一的时间只是在他们创建的文档中从一个位置导航到另一个位置。虽然研究人员已经检查了数字输入的最佳字符串长度[^1]，用于电话拨号场景的替代纠错策略[^2]以及各种反馈机制[^3,12]，但这些研究都没有关注涉及的问题浏览创建的文档。

最近，Suhm，Myers和Waibel讨论了多模式技术，用于纠正使用键盘，鼠标，手写笔和语音的识别错误[^14]。他们发现，多模式技术可以更快地纠正错误，但是他们的所有技术都使用基于触摸屏的导航，使用户只需简单地触摸他们想要修改的字词即可。同样，Danis等人开发了一个面向语音的编辑器，用户可以使用“指示和说话”方法在听写时改变插入点，但光标移动使用鼠标完成[^4]。

McNair和Waibel还探讨了纠错，但更明确地集中在基于语音的不正确词汇选择上[^11]。在确定导航命令的目标时，他们早期版本的基于目标的导航使用识别的单词以及每个单词的替代方案列表。他们报告了15％的失败率。更重要的是，如前所述，基于目标的导航不太可能证明对当前研究的重点任务有效。

Manaris和Harkreader探讨了使用语音识别作为产生击键和鼠标事件的替代机制，目标是为患有上肢运动控制障碍的个体开发替代数据输入技术[^10]。使用基于方向的导航命令完成导航，导航命令产生连续的光标移动（例如，“向左移动”，接着是“停止”）以及基于目标的命令，其将光标移动到屏幕的五个预定义区域中的一个（例如，离散运动）。使用他们的SUITEKeys软件的一个Wizard-of-Oz模拟进行了一项试验性研究，但没有报告包含在该系统中的导航机制的结果。

Christian，Kules，Shneiderman和Youssef在网络环境中探索了基于语音的导航[^4]。导航是通过说出作为附加材料链接的词语，或者通过说出与浏览器链接自动关联的数字来实现的。与基于鼠标的导航相比，这种基于目标的导航导致的错误极少，但任务完成时间明显更长。

最近，de Mauro，Gori，Maggini和Martinelli讨论了语音控制鼠标的设计[^6]。他们的系统根据简单的话语产生连续的动作。与用户说出完整命令的大多数实现（即，“向左移动”）不同，单个元音被映射到命令。结果，用户必须学习从命令（即，“向左移动”）到引起该命令被执行的发音（即，“A”）的适当映射。他们的系统还支持在窗口区域内进行基于目标的导航。因此，一旦光标位于窗口的标题栏上，就可以使用适合该特定上下文的几个命令，包括：最小化，关闭和移动。目前，文本文档中的导航仅支持使用连续的鼠标移动，并且没有提供关于导航机制功效的数据。

虽然基于语音的导航已被证明是有问题的，但相对较少的研究探索了基于语音的光标控制所涉及的问题。比较替代方案的数量更少，报告的实证结果更多，或为有效使用基于语音的光标控制提供了指导方针。本文将重点讨论影响生成连续光标移动的基于方向的命令的问题。

## 预测的游标

三种延迟可以与口头输入相关联。首先，个人必须对视觉信号发起口头回应。其次，个人必须说出所需的命令。第三，系统必须识别所说的话。在讨论与口头输入相关的延迟时，我们指的是这三个延迟的总和。

考虑到与口头命令相关的延迟，当发出“停止”命令时，移动的光标不会立即停止。这种延迟的每个组成部分可能因用户而异。可以实施各种解决方案来解决这些延迟问题：

1）系统不能提供任何帮助，要求用户在任何给定时间发出“停止”命令时估计光标停止在哪里。目前这种方法在一些商业产品中使用。

2）当正在处理“停止”命令时，系统可以补偿光标移动的附加距离。光标移动的速度是已知的。通过确定平均延迟，也可以确定光标在用户发出“停止”命令和系统识别该光标之间的平均距离。当“停止”命令被识别时，光标可以跳回适当的距离来补偿延迟。由于光标始终移动到目标之外（然后向后跳），因此此方法会增加选择目标所需的时间，延迟量等于延迟时间。

3）如果在任何给定时间发出“停止”命令，系统可以帮助用户估计光标所在的位置。通过确定光标在延迟期间移动的平均距离，可以将“预测光标”定位在实际光标前的适当距离处，以指示如果发出“停止”命令，光标可能停止的位置。这种方法不会增加选择目标所需的时间。

第一种解决方案已经用于某些商业产品，第二种解决方案人为地增加了选择时间。因此，我们选择比较当前研究中的第一个和第三个解决方案。我们实现的预测游标如下：

•我们的系统支持六种基本导航命令：左移，右移，上移，下移，停止和单击。  
•光标以每秒20像素的速度移动（即大约53mm/second）。

•由于各个人之间的延迟时间会有所不同，并且一旦光标到达目标，每个人可能会花费不同的时间发出“停止”（或“单击”）命令，用于预测光标的偏移量将被校准为每个个人用户。通过将常规光标移向小目标并在光标到达目标时让用户发出“停止”命令来完成校准。重复四次（每次向上，向下，向左和向右移动一次），并将光标实际停止位置与光标中心之间的平均距离用作预测光标偏移量。我们的参与者的平均偏移大约为25个像素（即，66nm或延迟光标以20像素/秒移动时为1.25秒）。

•光标未移动时，预测光标不可见（即只显示常规光标）。  
•当用户发出任何“移动”命令时，预测光标会出现在实际光标的旁边，并沿移动方向偏移适当的距离。例如，如果发出“Move right”命令，则预测光标将偏移到实际光标右侧的适当距离（参见图1）。  
•当“Stop”或“Click”命令被识别时，预测光标被隐藏。

![](/assets/3pic1.png)
图1：发出“右移”命令时预测光标的图示。 如果在任何给定时间发出“停止”命令，则右侧的箭头指示光标预期停止的位置。

## 实验

我们报告了一项研究的结果，该研究调查了几种可能影响使用组间实验设计的基于方向导航的功效的因素。本研究的目的是研究提供预测性光标的好处以及目标大小，距离和方向对定位光标所需时间，定位误差和用户信心的影响，如使用“停止“命令和用户满意度评级。这个实验的假设是：

H1：当目标尺寸足够小时，预测光标将对定位光标所需的时间产生重大影响。对于较大的目标，预测光标不会带来任何好处。  
H2：目标大小将对定位光标所需的时间，错误率和用户可信度产生重大影响。  
H3：距离将对放置光标所需的时间有重大影响。当目标足够大时，距离和时间之间的关系将是线性的。当目标变小时，距离将变小，距离和时间之间的线性关系将消失。  
H4：对角线运动必须使用水平和垂直运动来完成。由于对角线运动需要两个定位活动（一个水平线和一个垂直线），对角线运动会导致比直线运动更多的误差。当目标足够大时，对角线移动所需的时间将由光标移动的距离决定。当目标足够小时，对角线运动所需的时间将由目标的大小决定。  
H5：满意度评分（速度，准确性和舒适度）将有利于预测光标。

## 方法

### 参与者

招募了二十八个人参加这项研究。参与者被要求说英语作为母语，并且以前没有使用语音识别系统的经验。参与者不能有任何未矫正的视觉障碍或记录听力言语或认知障碍。有14名参与者是男性。参与者的平均年龄为21.8（标准差= 5.5）。十四名参与者使用预测性光标选择目标，而其余十四名使用标准光标。

### 设备

运行Windows NT的PC用于本研究。使用IBM ViaVoice（Millennium Edition）语音识别引擎处理口头命令。与软件交互时，参与者使用头戴式麦克风。使用Visual Basic开发的自定义应用程序提供了目标和自动记录时间，错误以及所有其他用户活动。根据参与者被分配的实验条件，该应用被配置为呈现标准光标（即，单箭头）或预测光标（参见图1）。

### 程序

采用组间设计，使每个参与者使用标准或预测光标。预测光标条件中的参与者通过校准过程被引导，以允许系统为每个个体定制预测光标偏移量。如上所述，平均偏移大约是25个像素。  
参与者总共选择了72个目标（三个目标尺寸和三个距离中的每个目标有八个位置）。目标按尺寸分组，每个模块按距离细分。对于每个距离，目标位于八个地点（见图2）。三个块完成的顺序是随机的。在每个块内，子块也被随机化。最后，八个地点的经历顺序在子块内被随机化。参赛者可以根据需要休息一下。  
准备好开始任务时，参与者发出“准备好”命令。此时，光标位于屏幕中间，目标出现在适当的位置，并启动内部计时器。参与者发出适当的命令将光标移动到目标上，然后发出“点击”命令。 “停止”命令可以，但不一定要在“单击”命令之前。如果在发出“Click”命令时光标不在目标内，则会记录错误，并且参与者必须重新定位光标并发出另一个“Click”命令。

### 独立和依赖变量

独立变量是：光标类型（即标准或预测光标），目标大小，距离和方向。光标类型被视为组间变量，一半参与者用标准光标完成研究，另一半用预测光标完成研究。目标大小被视为具有三个等级的主体内变量。目标是每边32毫米，64毫米和128毫米的平方（称为S1,2美元，3美元）。运动距离也被视为三个水平的内部变量。目标中心距目标中心起点1.9cm，3.8cm和7.6cm（称为D1，D2，D3）。最后，运动方向也被视为具有两个等级的主体内变量。虽然采用了八个地点，但我们关注的是使用单个垂直或水平移动（即直线移动，见图2位置1,3,5和7）可以达到的地点之间的差异，以及需要水平移动和垂直运动（对角线运动，参见图2的位置2,4,6和8）。
![](/assets/3pic2.png)  
图2：目标定位在相对于原始光标位置的八个方向上。

因变量包括将光标放在目标上并发出“点击”命令，定位精度，用户信心和用户满意度所需的时间。 “就绪”命令和“点击”命令之间的时间是为每个目标自动记录的。通过计算当光标不在目标上时发出的“点击”命令的数量来评估定位精度。通过计数发出的“停止”命令的数量来评估用户信心。当有足够的信心时，用户将通过发出“停止”命令来发出“点击”命令而不验证光标位于正确的位置。随着用户变得不那么自信，他们将在发出“Click”命令之前使用“Stop”命令来验证光标是否正确定位。最后，许多“停止”命令指示用户难以定位光标。使用三个问题评估满意度，这三个问题询问参与者对技术的速度和准确性的看法，以及他们使用该技术的舒适程度。

## 结果

### 定位精度

使用标准游标和预测游标选择目标时所产生的错误数的平均值和标准偏差分别报告在表1和表2中。利用重复测量方向，距离和目标尺寸的方差分析来评估游标类型的影响。游标类型对错误没有显着影响（F（1,26）= 0.41，n.s.）。 （F（2,52）= 29.28，p &lt;0.001; F（1,26）= 12.99，p &lt;0.002; F（2,52）= 1.96，大小和方向对误差都有显着影响， ns）。确定了两个重要的相互作用：方向/光标类型和大小/方向/光标类型。正如预期的那样，较小的目标和对角线移动都会导致更多的错误，支持H2和H4。

### 选择时间

使用标准和预测游标选择目标所需时间的平均值和标准偏差分别报告在表3和表4中。在分析之前对这些数据应用对数转换以解决数据的非正态分布。利用重复测量方向，距离和目标尺寸的方差分析来评估游标类型的影响。光标类型对选择目标所需的时间没有显着影响（F（1,26）= 0.11，n.s.）。方向，距离和大小均对选择目标所需时间有显着影响（F（1,26）= 144.06，p &lt;0.001; F（2,52）= 648.57，p &lt;0.001; F（2， 52）= 146.26，p &lt;0.001）。确定了三个重要的相互作用：方向/大小，距离/大小以及方向/距离/大小。正如预期的那样，较小的目标，较长的距离和对角线移动导致更长的选择时间。这些结果支持H2，H3和H4。 H1不受支持。
![](/assets/3tab1.png)
表1：使用标准光标完成的任务的平均错误率（圆括号中的标准偏差）。
![](/assets/3tab2.png)
表2：使用预测光标完成的任务的平均错误率（圆括号中的标准偏差）。
![](/assets/3tab3.png)
表3：使用标准光标完成的任务的平均任务完成时间（括号中的标准偏差）。
![](/assets/3tab4.png)
表4：使用预测游标完成的任务的平均任务完成时间（标准差m括号）。

### 用户信心（即使用“停止”命令）

使用标准光标和预测光标选择目标时发出的“停止”命令的数量的平均值和标准偏差分别报告在表5和表6中。利用重复测量方向，距离和目标尺寸的方差分析来评估游标类型的影响。光标类型对使用“停止”命令没有显着影响（F（1,26）= 0.30，n .s.）。大小和距离对使用“停止”命令都有显着的影响，但方向没有（F（2,52）= 25.59，p &lt;0.001; F（2,52）= 6.68，p &lt;0.002; F （1,26）= 0.15，ns）。确定了一个重要的相互作用：目标大小/方向。正如所料，较小的目标导致更多地使用“停止”命令。更长的选择时间，支持H2。出乎意料的是，更长的距离也导致更多地使用“停止”命令。
![](/assets/3tab5.png)
表5：使用标准光标完成的任务发出“停止”命令的次数的方式（括号中的标准偏差）。
![](/assets/3tab6.png)
表6：使用标准光标完成的任务发出“停止”命令的次数的方式（括号中的标准偏差）。
### 满意

报告问卷结果的平均值和标准偏差表7.两个样本t检验证实由于使用的光标参与者的类型而没有显着差异。
![](/assets/3tab7.png)
表7：使用标准游标和预测游标时速度的主观评级，“准确性和舒适度”。 等级从1（正值）到5（负值）提供。 标准偏差在括号内。

### 讨论

光标类型对选择时间，置信度或满意度没有影响，但在分析错误时涉及光标类型的两个显着交互。不幸的是，更详细的分析证实预测光标与对角线移动的更高错误率相关联。在目前的情况下，预测性光标不会显得有益。 H 1和H 5都不被支持。  

目标大小确实影响选择时间，错误和信心，为H2提供强有力的支持。距离对选择时间有影响，为H3提供部分支持，但距离和大小之间的相互作用必须更详细地进行探讨，以确定H3是否完全得到我们的数据支持。下面提供了这个额外的分析。出乎意料的是，距离也对用户的信心产生了重大影响，用户在将光标移动更远的距离时发出更多的“停止”命令。方向对错误和时间产生影响，为H4提供部分支持，但必须更详细地探讨涉及规模和方向的相互作用，以确定H4是否完全得到我们的数据支持。这个分析也在下面提供。  

由于预测游标没有提供任何好处，因此本讨论的其余部分将集中讨论参与者使用标准游标时获得的结果。目标是提供见解，可用于设计更有效的基于语音的光标控制机制以及给定现有基于语音的光标控制机制的更有效的接口。  

选择目标包括将光标移动预定义的距离，将光标定位在目标上，然后发出“单击”命令。 由于光标只能水平或垂直移动，下面的分析使用光标实际移动的距离来完成选择而不是直线距离。 因此，直线运动的距离分别为1.9厘米，3.8厘米和7.6厘米，而对角线运动的距离分别为2.7厘米，5.4厘米和10.7厘米。 直线运动需要单个定位活动，并且可以用少至两个命令（即，以正确方向“移动”和“点击”）来完成。 对角线移动需要两个定位活动（即，一个水平和一个垂直），并且将需要至少三个命令（例如，“水平移动”，“垂直移动”和“点击”）。  
选择目标包括将光标移动预定义的距离，将光标定位在目标上，然后发出“单击”命令。由于光标只能水平或垂直移动，下面的分析使用光标实际移动的距离来完成选择而不是直线距离。因此，直线运动的距离分别为1.9厘米，3.8厘米和7.6厘米，而对角线运动的距离分别为2.7厘米，5.4厘米和10.7厘米。直线运动需要单个定位活动，并且可以用少至两个命令（即，以正确方向“移动”和“点击”）来完成。对角线移动需要两个定位活动（即，一个水平和一个垂直），并且将需要至少三个命令（例如，“水平移动”，“垂直移动”和“点击”）。 
 
当目标足够大时（大目标）：  

选择目标所需的时间是光标必须移动的距离的线性函数（r2 = 0.98，图3）。回归方程导致Y轴截距仅为3.87，斜率为5.56，表明每厘米光标必须移动需要5.56秒。  
将光标放在目标上很容易。这通过低错误率（0.06错误/目标，图4）和“停止”命令（0.24命令/目标，图5）的有限使用来说明。小的Y截距（3.87，图3）也支持这种观察。  
直线和对角线运动之间的差异很小。如图3所示，缺少有关方向变量的显着差异以及距离和选择时间之间的强烈线性关系。  
![](/assets/3pic3.png)
图3：使用标准光标（以秒为单位）选择各种尺寸目标所需的时间，距离原始光标位置有多个距离。
![](/assets/3pic4.png)
图4：使用标准光标选择各种尺寸的目标时的平均错误率。
![](/assets/3pic5.png)
图5：使用标准光标选择各种尺寸的目标时发出的“停止”命令的数量

随着目标变得更小（中等目标）：  
•距离和时间之间的关系仍然是线性的（r2 = 0.95，图3），但Y截距增加到10.88。斜率增加到6.69。  
•将光标准确定位在目标上更加困难。错误增加（0.23错误/目标，图4），使用“停止”命令增加（1.23命令/目标，图5），Y截距更大（10.88，图3）。  
•由于定位光标更加困难，并且对角线移动需要两个定位活动，所以对角线移动开始花费的时间比同一距离的直线移动更长。这可以通过对应于对角线移动的图3中的中等目标线上的5.4cm和10.7cm的颠簸来说明。  
当目标变得如此之小时，使用当前的定位命令（小目标）无法有效地选择目标：  
•时间和距离之间的线性关系较弱（r2 = 0.58），Y截距为33.15，斜率为8.05。代表定位时间（与移动时间相对）的Y轴截距显着增加，变化更大，并且开始主导选择目标所需的总时间。  
•将光标放在目标上更困难。错误显着增加（0.71错误/目标，图4），使用“Stop”命令显着增加（3.32命令/目标，图5），Y截距更大（33.13，图3）。  
•由于定位光标非常困难，而且对角线移动需要两个定位活动，所以人们会预期对角线移动花费的时间会比相同距离的直线移动要长。有趣的是，这并没有发生。事实上，如图3中沿着小目标线的三个峰所示，直线运动实际上需要比对角线运动更长的时间。这表明，对于这种尺寸的目标，选择时间不再是用户必须移动光标的距离的函数。  
总的来说，这些结果似乎证明了对H3的有力支持。 H4的结果是混合的。正如预测的那样，选择时间主要由光标在目标足够大时必须移动的距离决定，而当目标变小时定位时间变得更加重要。然而，与直线移动相比，对角线移动不会导致错误率的增加。看来用户只是花费更多时间来确保这些任务的错误没有增加。

### 结论

预测游标没有提供预期的好处。我们认为这可能是由于相对较短和一致的延迟，使标准光标条件下的用户可以预测光标在任何给定时间将停止的位置。用户体验选择目标的难度似乎是光标移动速度，目标大小和延迟本身的结果。  
在目前的研究中，光标以20像素/秒的速率移动。结果，用户在选择小目标时发出“停止”命令的时间约为0.6秒，以确保光标与目标重叠（中等目标为1.2秒，大目标为2.4秒）。正如所料，与大型目标相比，用户在精确选择大型目标时几乎没有困难，而中型目标导致更多地使用“停止”命令，更多错误和更长的选择时间。大型和中型目标的选择时间和距离之间的强烈线性关系表明，大型和中型目标都足够大，以至于我们的参与者可以可靠地选择目标。  
小目标会导致更多的“停止”命令使用，更高的错误率，甚至更长的选择时间。更重要的是，距离和选择时间之间的线性关系要弱得多，定位时间（Y截距）占总选择时间的很大一部分。虽然定位光标显然是困难的，并且对角线移动需要两个定位活动，但直线移动需要比相同距离的对角线移动更多的时间。这些结果表明我们的参与者不能可靠地选择小目标。  
当前基于语音的光标控制机制允许用户可靠地选择相对较大的目标，但不能很快。未来的研究必须研究能够可靠地选择较小目标的机制，同时允许更快地选择所有目标。目前正在进行一些跟进研究，这些研究将提供关于光标速度，目标大小以及与口头输入相关的延迟对选择时间和错误率的影响的更多见解。鉴于与口头投入有关的延迟的重要性，正在进行的其他研究将提供对这一延迟的三个组成部分每一个的大小的深入了解。

### 致谢

本资料基于美国国家科学基金会资助项目IIS-9910607和IIS-0121570的支持。本资料中所表达的任何意见，发现和结论或建议都是作者的观点，并不一定反映国家科学部门的观点基金会（NSF）。我们还要感谢UMBC Provost本科生研究计划提供的支持。

### 参考文献

1. Ainsworth, W. A. \(1988\). Optimization of string length for spoken digit input with error correction. International Journal of Man-Machine Studies, 28, 573- 581.
2. Ainsworth, W. A. and Pratt, S. R., \(1992\). Feedback Strategies for Error Correction in Speech Recognition Systems. International Journal of Man-Machine Studies, 36, 833-842.
3. Baber, C. and Hone, K. \(1993\). Modeling error recovery and repair in automatic speech recognition. International Journal of Man-Machine Studies, 39, 495- 515.
4. Christian, K., Kules, B., Shneiderman, B. and Youssef, A. \(2000\). A comparison of voice controlled and mouse controlled web browsing. Proceedings of Assets 2000, pp. 72-79.
5. Danis, C., Comerford, L., Janke, E., Davies, K., Devries, J. and Bertrand, A. \(1994\). Storywriter: A Speech Oriented Editor, CHI 94 Conference Companion. pp. 277-278.
6. de Mauro, C., Gori, M., Maggini, M. and Martinelli E. \(2001\). Easy access to graphical interfaces by voice mouse. Available from the author at: demauro@dii.unisi.it
7. Halverson, C., Horn, D., Karat, C-M. and Karat, J. \(1999\). The beauty of errors: patterns of error correction in desktop speech systems. Proceedings of INTERACT'99. lOS Press, pp. 133-140.
8. Hauptmann, A. G. \(1989\). Speech and gestures for graphic image manipulation. Proceedings of CH1'89, pp. 241-245.
9. Karat, C-M., Halverson, C., Karat, J. and Horn, D. \(1999\). Patterns of Entry and Correction in Large Vocabulary Continuous Speech Recognition Systems. Proceedings of CH199, pp. 568-575.
10. Manaris, B. and Harkreader, A. \(1998\). SUITEKeys: A speech understanding interface for the motor-control challenged. Proceedings of the 3rd International ACM SIGCAPH Conference on Assistive Technologies \(ASSETS'98\), pp. 108-115.
11. McNair, A. and Waibel, A. \(1994\). Improving recognizer acceptance through robust, natural speech repair. Proceedings of the International Conference on Spoken Language Processing, pp. 1299-1302.
12. Noyes, J. M. and Frankish, C.R. \(1994\). Errors and error correction in automatic speech recognition systems. Ergonomics, 37, 1943-1957.
13. Sears, A., Karat, C-M., Oseitutu, K., Karimullah, A. and Feng, J. \(2001\). Productivity, satisfaction, and interactiorr-strategies of individual with spinal cord injuries and traditional users interacting with speech recognition software. Universal Access in the Information Society, 1, 4-15.
14. Suhm, B., Myers, B. and Waibel, A. \(2001\). Multimodal error correction for speech user interfaces. ACM Transactions on Computer-Human Interaction, 8\(1\), 60-98.



