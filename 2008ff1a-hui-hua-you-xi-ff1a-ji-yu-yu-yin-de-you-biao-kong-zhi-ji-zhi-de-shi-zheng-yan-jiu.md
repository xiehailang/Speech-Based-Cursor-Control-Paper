#会话游戏：基于语音的游标控制机制的实证研究
**摘要    **本文档描述了基于语音的光标控制机制以及称为NameTags的新建议方法的研究。本研究旨在提供经验用户数据，以通知未来系统的设计，其中存在以下一个或多个条件：实时需求，非常小的目标和移动目标。这项研究的一个这样的应用是在视频游戏领域，在这些领域中，被摄体通常需要快速选择许多小的移动物体。 这些发现也对身体受损的受试者有影响，他们的主要或唯一控制形式是言语。

##第1章介绍和背景
###1.1简介
光标控制是现代计算机界面的基本方面，特别是那些交互风格是方向操纵的控件。自20世纪80年代初商业引入以来，鼠标一直是前期光标控制设备，但它并不总是可用或最佳的。许多身体有缺陷的用户可能更喜欢或需要基于语音的界面来进行光标控制。即使没有身体障碍的用户也可能会发现基于语音的光标控制在某些情况下是有用的或可取的。还有一些人可能更喜欢多模式方法，利用语音和鼠标（或其他指示设备）一起来实现光标控制。

一旦选择了目标对象，用户可以操纵该对象。当使用光标控制时，用户可以拖动对象或指向目标位置（例如Windows回收站或子文件夹）。本研究的重点是改进基于语音的光标控制，以实现对象选择和空间导航。以下部分提供了与本研究相关的基于语音的光标控制的背景。

###1.2背景
作为界面形式的演讲并不新鲜。但是，通过语音进行全面的PC控制是一个更大的挑战。 Oviatt [^25]的研究发现文本输入和光标控制是这种语音系统必须支持的两个关键要素。第一个比第二个更容易，因为语音识别系统的最新进展已经在受控环境下将识别准确率提高到98％，这使得它们成为听写的有力工具[^13]。另一方面，光标控制不像自然地映射到语音。事实上，如果这样的系统设计得不好，语音和识别错误率的固有延迟可能会使屏幕上的对象指向一个乏味的任务。Sears[^31]的研究发现，使用听写软件的用户花费了三分之一的时间浏览目标位置。因此，光标控制性能的任何改进都会对总任务完成时间产生重大影响。

这方面的一些研究集中在“以目标为基础”的指向上;即在屏幕上选择一个预定义的标记点[^6,17,18,19]。其他人采用“基于方向”的方法，其中用户给出相对于当前光标位置的方向命令[^14,16,20,21,22,24]。

基于方向的光标控制可以细分为两种类型：离散和连续。离散光标控制允许用户说出诸如“向左移动2英寸”的命令。研究表明，当光标远离目标位置[^20]时，这种方法变得不那么有效。连续光标控制要求用户指定一个方向（也许是一个速度），将光标“驱动”到所需的位置。一旦光标到达目标，用户说“停止”或类似的命令来停止光标的移动。然而，这种方法导致3种类型的延迟：

•与用户察觉光标已到达目的地相关的延迟
•与用户发出停止命令相关的延迟
•与语音识别引擎处理用户命令相关的延迟

因此，用户必须预测光标停止的位置，并在光标到达目标之前发出“停止”命令。 Karimullah [^20]提出了一种方法，它显示一个“幻影光标”以及实际的光标，指示在给定时刻用户说“停止”时光标最终会到达的位置。

这个主题的一个变体是使用“非语言”或口头声音（如哼唱）来移动光标[^14,33,16]。原田的人声操纵杆允许用户选择元音来选择方向（例如，左边是“ee”，右边是“ahh”），音量用于控制光标速度（为了更快的移动，声音更大）。 Mihara [^24]提出了一种称为迁移光标的混合方法，该方法使用非语音以及基于方向和基于目标的光标控制的混合。

Feng [^7,8]在听写系统中研究了基于语音的导航。Feng的工作试图改善错误预防和恢复。研究发现，虽然基于方向的和基于目标的方法的失败率没有显着差异，但基于方向的任务更可能失败，因为他们需要更长的命令序列才能到达目标位置。

这项研究主要关注基于目标的光标控制，现在将对其进行更详细的讨论。

基于目标的光标控制直接将光标“跳转”到目标位置。例如，Kamel和Landay [^17,18,19]为盲人开发了基于语音的绘图工具，采用3x3网格叠加。 Dai et al。 [^6]建立在这项工作基础上，将其应用于有远见的用户。前述的网格叠加是基于目标的解决方案，网格中的每个单元都分配有1到9的数字。用户发出期望的数字以指向屏幕上的特定点。然后显示一个较小的网格来代替所选的单元格。用户递归地发出命令，直到目标对象（只有目标对象）被包含在突出显示的区域内，然后说“点击”或类似的命令来模拟在该点上的鼠标点击。这种基于网格的方法允许用户指定屏幕上的任何点，但非常小的对象可能需要多达7条命令才能在1024 x 768分辨率屏幕上进行隔离。网格光标的屏幕截图如图1.1所示。
![](/assets/2004pic1.png)
图1.1：网格光标控制机制的屏幕截图。 在这个例子中，用户想要选择灰色物体。 用户说“一个”，网格缩小到该单元位置。 用户再次说“one”，然后是“select nine”。

Christian等人。 [^3]使用基于目标的光标控制来浏览网页浏览器，既可以让用户说出链接的文本，也可以用一个数字标记每个链接。两种方法在完成时间或主观满意度方面没有显着差异，但用户更喜欢说实际链接的文本，而不是编号标签。

言语系统可使身体有缺陷的个人在本来无法实现的领域获得就业机会。事实上，Jeffrey Gray的SpeechClipse [^12]这样的系统是Eclipse编程环境的语音启用版本，它提供的快捷方式可以提高性能，甚至可以为没有物理损伤的用户提供主观满足感。虽然这项研究是在没有任何记录残疾的对象的情况下进行的，但它的发现可能提供有趣的比较数据。

多模式系统在过去几年已成为增加研究的焦点，尽管他们早在1980年就已经进行了研究，当时Hauptmann [^15]发现令人鼓舞的结果是用户准备好混合语音和手势。多模式研究旨在将新的和创新的控制机制与标准操纵杆或键盘和鼠标控制范例相结合。诸如[^34]和[^32]等研究项目已经探索了使用眼睛注视来指示光标，而任天堂Wii，其特征是基于运动的控制与经典的控制机制混合在一起，已售出超过900万个[^29]。 Perakakis在PDA上使用多模式输入模式进行的研究发现，用户倾向于关注最有效的输入模式。然而，这项研究对视频游戏领域有特别的兴趣，用户可以使用一种更有趣的输入模式，而这种输入模式的效率稍微高一点。

下一节将介绍所提议方法的当前问题。

###1.3问题描述
上述研究主要关注绘制形状，浏览网页或听写的应用程序。即使在那些以游戏形式实现实验的研究[^2,35]中，用户不受时间限制，目标位置也是静止的。然而，在许多系统中，目标对象可能不是固定的，而是可能以可预测的模式（甚至是随机的）移动。此外，要选择的对象可能只有几个像素宽和/或长，这使得基于网格的解决方案不太适合实时情况。而且，许多程序显示没有文本标签的可选对象。在这种情况下，Christian [^3]提出的编号系统可能适用于屏幕上的少量可选对象。随着对象数量的增加，随着诸如“十四”和“四十”等标签听起来太类似，整数的识别错误率将增加。

在这种情况下，NameTags控制机制为这些对象提供了一个文本“句柄”。下一节将介绍如何使用NameTag。

###1.4 NameTags
NameTags是一种基于标签的游标控制机制，它为标签库使用通用名称。用户可以切换一个“姓名标签”选项，为屏幕上的每个可选单位添加标签，为玩家提供一个口头“处理”来引用他们（图1.2）。使用这种控制机制来选择对象很简单。例如，用户可以说，“选择鲍勃，大卫和苏珊”。这种解决方案平衡了区分不同对象的需要，而不会在屏幕上显示细节（因为它可以被切换）。
![](/assets/2008pic2.png)
图1.2：Left，来自Warcraft 3的屏幕截图，显示了几个不同类型的单元。 正确的，相同的图像，但与单位“标记”的名称。

使用这种机制将单位移动到屏幕上的给定点也同样简单。用户可能会使用其他对象作为“航点”或“领导者”发出类似“移至凯文”或“关注苏珊”的命令。然而，这种机制并没有提供像Grid Cursor机制那样指向屏幕上的任意点（没有可选对象的点）的方法。因此，NameTags必须与另一种机制相结合，才能实现全面的PC控制。

在这种方法中使用名称不是简单的任意。由于几个数字和字母听起来相似（例如像“B”，“V”和“D”的字母以及像“十四”和“四十”这样的数字），所以带有数字或字母的标签单元可能导致识别错误的机会更大。而命名带有“Kevin”和“Mark”标签的单位可能会提供更多不同的音素。此外，如果可选单位的意图是表现为拟人化（如本研究），使用名称可能更适合玩家。自然地，随着屏幕上的对象数量的增加，识别错误率预计会增加。单词和数字的组合可能会产生听觉独特性和简洁性之间的最佳平衡，但这是未来工作的主题。

###1.5贡献
这项研究涉及通过比较三种控制机制来改进基于语音的光标控制：操纵杆，基于网格的光标控制以及称为NameTags的基于标签的机制。 在每个实验中，受试者使用这些机制（独立和/或组合）在屏幕上选择和移动对象。 测量并分析受试者的表现和偏好（包括报告和实际）。 本研究旨在提供经验用户数据以及该数据的解释，以便为将来存在以下一种或多种情况的未来系统的设计提供信息：实时需求，非常小的目标和移动目标。

##第2章 游戏杆与网格光标实验

本章详细介绍了比较光标控制的两种不同机制的实验 - 标准操纵杆（又名“游戏手柄”）和基于语音的光栅游标。 这是三个旨在比较基于语音的光标控制方法的性能和可用性与当前主流模式的实验中的第一个。
由于操纵杆是视频游戏中的主要光标控制设备，因此该实验试图找到用于预测操纵杆性能与基于语音机制的模型。 Fitts的法则被选中是因为它是一种成熟的指向设备模型。
Fitts定律[9]是Fitts在1964年开发的精神运动行为模型。它描述了人类用户使用手动输入设备获取目标所需的时间。 虽然它最初是为一维运动而制定的，但研究人员发现它即使在二维任务中也很稳健。

2.1实验设计2.1.1假设
本实验旨在回答以下问题：
•这两种机制的性能如何比较？
•这些机制是否遵守Fitts定律的运动时间？ 
•受试者喜欢哪种机制？
测试了以下假设：
•游戏杆在完成时间内胜过网格光标。
•操纵杆将严格遵守费茨定律（大于0.90皮尔森的相关性）。
•修改公式后，网格光标将严格遵守费茨定律（大于.80皮尔逊的相关性）。
2.1.2主题
该实验共有40名受试者，17名女性和23名男性，平均年龄为25.3岁。这些科目选自杰克逊维尔州立大学的学生团体和教职员。受试者不需要专业知识或经验参与这项研究。图2.1显示了每周的主题计算机使用和游戏玩法。如所示，没有主题报告“无”用于计算机使用。游戏的每个类别也都有很好的表现。

2.1.3设置
要求受试者玩简单的游戏，其中他们的唯一目标是尽快选择屏幕上的静止物体。为了测试这两种机制，选择了一个受试者内部设计，使得一半受试者首先使用网格光标，其次是操纵杆，而另一半则反过来。每个科目使用每种机制执行50个选择任务。受试者被给予关于如何玩游戏的基本指示，然后被允许在开始游戏之前练习给定的3个试验任务的机制。
该游戏的语音控制组件在CloudGarden [4]中实现，该版本是Java Speech API的一个版本。游戏本身是在Game Maker [11]中编写的，这是一个简单的二维游戏引擎。语音组件和游戏之间的通信由Java Robot类生成的按键消息来促进。
图2.2描述了游戏的两个屏幕截图。游戏的游戏杆版本显示在左侧，Grid Cursor显示在右侧。
为了减轻语音识别错误，受试者在使用网格光标之前完成了微软语音识别训练向导的介绍性会话。
使用网格光标时，主体可以发出以下命令：•缩小网格：“<1 - 9>”示例命令：“4”
•选择对象：“选择<1 - 9>”示例命令：“选择两个”
•返回：“返回”或“返回”
选择一个对象会发生如图2.3所示。
使用操纵杆时，可使用以下控件：•移动光标：移动方向板
•选择对象：按下按钮“A”
驾驶员测试后，操纵杆的移动速度设置为210像素/秒。在每个游戏关卡开始时，游戏杆光标被重置到屏幕中央。
2.1.4对象大小和放置
将要选择的对象随机放置在屏幕上，并且在1024×768,17英寸屏幕上随机地放置在20像素和100像素正方形之间。大小范围来自一个流行的基于回合的战略游戏Galactic Civilizations [10]。选择这种游戏类型是因为可选对象保持静止，这对于测试Fitts法则的遵守是必要的。使用静止物体进行测试还为将来与移动物体进行实验提供了基准。
2.1.5问卷
游戏结束后，要求受试者填写问卷，询问受试者以下信息：
•年龄
• 性别
•受试者每周使用电脑多少时间
•主题每周播放视频游戏的时间
受试者也被要求评估他们对每个控制机制的主观印象。摘录如图2.4所示。

2.2结果
2.2.1性能比较
游戏杆在完成时间内的表现优于网格游标，平均完成时间为2.178秒，而网格游标为7.634。进一步的细节如图2.5所示。
操纵杆在完成时间方面是明显的赢家。然而，需要注意的是，该实验强制要求网格光标，如果放松，会导致更快的平均性能。图2.6说明了这一要求。
为了模拟最坏情况下所需的指示时间，这个要求被强制执行：屏幕上充满了大量紧密排列的可选对象。在这种情况下，主体将被迫像在实验中那样使用网格光标。然而，为了尽可能匹配默认的费茨法则实验设置，只有目标可选对象被显示在屏幕上。

性能数据的单因素方差分析检验发现，男性和女性之间在性能上差距很大（α= 0.05，F = 10.30，P = 0.003）。男性受试者的平均选择时间为1.903，而女性受试者的平均选择时间为2.533。这可能是因为玩视频游戏花费了数小时，因为游戏杆的表现也高度依赖于玩游戏的时间。这些细节如图2.7所示。图2.8显示了按性别划分的每周游戏玩法比较。
通过综合考虑这两个因素，似乎显然性别在操纵杆性能上几乎没有或没有意义。相反，我们样本中的男性每周玩游戏的时间比女性多。这两个因素的相互作用如图2.9所示。
另一方面，言语表现高度依赖于使用计算机的时间（F = 3.61，P = 0.037），但不是花在玩视频游戏上的时间。
2.2.2坚持费茨法则
如实验所示，该实验采用了Fitts定律的香农公式。
Fitts定律的香农公式被选中，因为预测的运动时间总是非负的。在这个公式中，T是指运动时间，D是从光标到物体中心的距离，W是物体的宽度。常数a和b可以通过线性回归确定，它们代表设备的启动/停止时间和设备固有的运动速度。由于费茨法则最初是为一维运动而设计的，因此必须进行一些修改。 Mackenzie [23]比较了二维任务的费茨法则公式的几种变化，本实验采用以下方法：
距离由光标到物体中心的欧几里得距离决定。
•宽度由高度或宽度中的较大值决定（实际上，由于要选择的对象是正方形，因此在我们的实验中未做任何说明）。
如图2.10所示，操纵杆紧紧贴合Fitts定律，皮尔逊相关系数为0.912。
回归方程是选择时间=
性能数据的单因素方差分析检验发现，男性和女性之间在性能上差距很大（α= 0.05，F = 10.30，P = 0.003）。男性受试者的平均选择时间为1.903，而女性受试者的平均选择时间为2.533。这可能是因为玩视频游戏花费了数小时，因为游戏杆的表现也高度依赖于玩游戏的时间。这些细节如图2.7所示。图2.8显示了按性别划分的每周游戏玩法比较。
通过综合考虑这两个因素，似乎显然性别在操纵杆性能上几乎没有或没有意义。相反，我们样本中的男性每周玩游戏的时间比女性多。这两个因素的相互作用如图2.9所示。
另一方面，言语表现高度依赖于使用计算机的时间（F = 3.61，P = 0.037），但不是花在玩视频游戏上的时间。
2.2.2坚持费茨法则
如实验所示，该实验采用了Fitts定律的香农公式。
Fitts定律的香农公式被选中，因为预测的运动时间总是非负的。在这个公式中，T是指运动时间，D是从光标到物体中心的距离，W是物体的宽度。常数a和b可以通过线性回归确定，它们代表设备的启动/停止时间和设备固有的运动速度。由于费茨法则最初是为一维运动而设计的，因此必须进行一些修改。 Mackenzie [23]比较了二维任务的费茨法则公式的几种变化，本实验采用以下方法：
距离由光标到物体中心的欧几里得距离决定。
•宽度由高度或宽度中的较大值决定（实际上，由于要选择的对象是正方形，因此在我们的实验中未做任何说明）。
如图2.10所示，操纵杆紧紧贴合Fitts定律，皮尔逊相关系数为0.912。
回归方程是选择时间=
在测试网格光标遵守Fitts定律时，直观地看到距离不是一个有用的参数，因为网格光标覆盖整个屏幕。大小似乎是决定选择时间的主要参数。为了测试这一点，最初的香农公式和两个变体都是针对观察选择时间进行测试的。他们被显示。
•选择时间= a + b log（D + 1）原始配方2W
•选择时间= a + b log2（D + 1）单独距离•SelectionTime = a +博客（1 +1）SizeAlone
在表2.1和图2.11,2.12和2.13中以表格和图形格式显示了这些制剂中的每一种的适合性。在考虑尺寸作为唯一因素时，发现了最紧密的拟合，其次是原始香农公式和“仅限距离”公式。

2.2.3主题偏好
正如实验后调查问卷的摘录中所描绘的，40名受试者被要求根据以下6个双相语义类别对游戏杆和网格光标进行评分：
•无聊或乐趣
•独立或参与
•难以控制或易于控制
•令人沮丧或愉快•不自然或自然
•复杂或简单
网格光标在6个类别中获得了比操纵杆更高的平均分数。然而，在6个测试类别中，只有2个具有统计显着性，α值为0.05。受试者评估操纵杆更简单（P = .000），而网格光标被评为更具吸引力（P = .001）。结果如图2.14所示。
女性受试者在单因素方差分析测试中（α= 0.05，F = 8.03）评估操纵杆比男性受试者更接近（平均值= 3.71，标准偏差= 0.772）（平均值= 2.81，标准偏差= 1.09） ，P = 0.007）。网格光标的评分被逆转（F = 4.31，P = 0.045），男性对网格光标的评价比女性更接近（平均值= 4.23，标准偏差= 0.685）（均值= 3.65，标准偏差= 1.06）。
2.2.4结论
本部分简要介绍了此实验的结果。
游戏杆在平均选择时间内的表现优于网格游标的3.5倍，但应该注意的是这是一种最糟糕的表现。但是，即使在最佳环境下，操纵杆也是表现的明显优势。因此，只有当操纵杆不可访问或时间不是因素时，网格光标才有用。
毫不奇怪，操纵杆的表现高度依赖于受试者每周玩电子游戏的时间。言语表演高度依赖于被试使用电脑的时间。

操纵杆紧紧贴合Fitts定律，皮尔逊相关系数为0.912。 网格光标并没有像操纵杆一样紧密，尽管它在使用尺寸作为唯一的输入参数时提供了最紧密的匹配（相关性为0.696）。
当对受试者偏好进行测试时，网格光标在6个类别中获得了比操纵杆更高的平均得分。 操纵杆被评为更简单，而网格光标被评为更具吸引力。 这表明，尽管网格光标在完成时间方面表现较差，但在某些情况下，主体可能更喜欢在操纵杆上使用此机制。

女性受试者评价操纵杆比男性受试者更有吸引力，而男性受试者评价栅格光标比女性受试者更有吸引力。 这可能意味着，根据心理学家Mihly Cskszentmihlyi关于“流量”[5]的研究，许多用户在受到挑战时最需要参与。

##第五章结论和未来工作
本章涵盖整体研究结论以及对未来工作的想法。

###5.1结论
在实验1中，测试了以下假设：

•游戏杆在完成时间内胜过网格光标。
•操纵杆将严格遵守费茨定律（大于0.90皮尔森的相关性）。
•修改公式后，网格光标将严格遵守费茨定律（大于.80皮尔逊的相关性）。

第一和第二个被证明，但第三个不是。下面显示了这个的更多细节以及主题偏好结果。

游戏杆在平均选择时间内的表现优于网格游标3.5倍，使游戏杆成为完成时间的明显赢家。因此，只有当操纵杆不可访问或时间不是因素时，网格光标才有用。游戏杆表现高度依赖于受试者每周玩电子游戏的时间。言语表演高度依赖于被试使用电脑的时间。由于这两个因素，有可能刚开始使用游戏但熟悉计算机的用户可能更喜欢使用网格光标。网格光标比6种主观偏好类别中的4种，尤其是“参与”类别中的操纵杆获得更高的平均评级，这一点得到加强。

操纵杆紧紧贴合Fitts定律，皮尔逊相关系数为0.912。这意味着操纵杆的表现时间可以高度准确地预测，与其他指针设备（如鼠标和触控板）非常相似。
网格光标并没有像操纵杆一样紧密，尽管它使用尺寸作为唯一的输入参数时提供了最紧密的匹配（相关性为0.696）。这不符合0.80的目标。

女性受试者评价操纵杆比男性受试者更有吸引力，而男性受试者评价栅格光标比女性受试者更有吸引力。鉴于男性受试者的完成时间明显短于女性对手的这一事实，这可能意味着许多用户在受到挑战时最需要依照心理学家Mihly Cskszentmihlyi关于“流动”的研究[5] 。

在实验2中，测试了以下假设：
•在选择时间内，NameTags将胜过操纵杆。
•NameTags的性能会随着对象尺寸的减小而增加。
•操纵杆的运动时间将超过网格光标。
•语音机制（NameTags +网格光标）将优于操纵杆。
•NameTags将优先于网格光标。

第一个假设是错误的，而另外四个是被证明的。下面显示了这个的更多细节以及主题偏好结果。

总体而言，操纵杆在选择静止物体方面的表现略胜于NameTags。但是，对于小于44像素平方的对象，NameTags胜过操纵杆。 NameTags选择时间的变异性也较小，因为它不受距目标对象距离的影响。这表明NameTags在目标对象较小的系统中非常有效。

游戏杆再次证明比物体移动时的网格光标更有效。

对于6个类别中的4个，受试者比操纵杆给出了更高的评级，其中3个具有统计显着性。受试者的评分比操纵杆更有趣，更有吸引力，更令人愉快。这意味着，如果球员设计正确，球员可能会接受言论作为主要形式。

女性受试者对言语的评价较男性受试者容易控制且更令人愉快。也许这是一个迹象表明，女性玩家会喜欢比目前提供更多的语音控制，尽管这值得进一步研究。受试者每周花在使用电脑或玩游戏上的时间越多，他们对语音的评价就越低“简单”。受试者玩游戏的时间越多，他们认为言语自然也就越少。这些都可能表明已经熟悉特定控制模式的用户（例如，鼠标，键盘，操纵杆）可能不愿意采用新的不熟悉的模式。

主题狭义地首选NameTags到网格光标。女性受试者将NameTags评为比男性受试者更有趣，更愉快，更容易控制。与一般言论一样，玩游戏和NameTags的“易于控制”评分的时间呈反比关系。

在实验3中，测试了以下假设：

•在具有多个移动目标物体的环境中，多模式控制将优于整个操纵杆。
•在具有多个移动目标对象的环境中，主题会偏好操纵杆上的NameTags以进行对象选择。
•在具有多个移动目标物体的环境中，受试者会偏好多模式控制。

所有这三个假设都被证明了。下面显示了这个的更多细节以及主题偏好结果。

多式联运控制的水平完成时间优于操纵杆25.7％。此外，结果表明，这种绩效差距只会随着目标对象数量的增加而扩大。这表明，当需要高性能时，多模式控制是可取的。

受试者绝大多数喜欢在操纵杆上进行对象选择的NameTags，84％的时间使用它。主体偏好网格光标上的操纵杆以便进行对象移动;然而，值得注意的是，那些确实使用栅格光标的主题往往会在整个游戏中继续使用它。

与前面两个实验一样，单因素方差分析显示男性受试者使用操纵杆比女性受试者跑赢了。这种性能差异对于多模式控制也是如此，尽管这可能是因为花在玩视频游戏上的时间。另外，由于多模式完成时间的斜率在第一次下降后几乎平稳，所以即使是经验适中的玩家也可以巧妙地使用多模式控制。对于试图融入语音控制的视频游戏开发者来说，这是一个很有希望的结果。

对于所有6个类别，多模式控制的平均评分均高于操纵杆。 6个测试类别中有5个具有统计显着性。受试者评估多模式更有趣，更吸引人，更容易，更愉快，更自然。

简而言之，多模式控制（语音+操纵杆）比单独的操纵杆产生更高的性能和更高的主观满意度。这说明强烈赞成在与被测试环境类似的环境中进行多模式控制。

###5.2未来的工作
百分之八十五的受访者从未使用过语音控制。正因为如此，我们无法发现有经验的言语用户在表现和偏好方面与经验不足的人有何不同。未来的研究可能包括使用语音控制的经验丰富的用户。另外，时间限制限制了游戏级别的数量。多次延长的会议可能会发现本研究中未发现的有趣趋势。例如，操纵杆是大多数用户熟悉的控制机制，而语音控制通常是新颖的。由于用户具有更多的言语体验，他们对易用性和有吸引力的质量的看法可能会发生变化。

由于本研究中的大部分科目都是传统大学生，因此很少有关于年龄如何影响用户表现和偏好的信息。未来的研究可能包括分布广泛的年龄组，以发现新的信息。例如，非传统玩家可能更喜欢言语，因为他们对游戏杆几乎没有经验。另外，尽管语音控制在过去被证实对于运动技能障碍的用户有用，但是老年用户也可能更喜欢言语而不是与操纵杆所需的眼手协调搏斗。

将这些语音机制与针对残疾用户的其他软件工具一起进行测试以发现新的意想不到的协同作用也很有趣。

##参考文献
[1] Blizzard Entertainment, Inc. Warcraft III: Reign of Chaos. www.blizzard.com, 2003.

[2] Buisine, S. and Martin, J. 2005. Children’s and Adults’ Multimodal Interaction with 2D Conversational Agents. CHI 2005, 1240-1243.

[3] Christian, K., Kules, B., Schneiderman, B., and Youssef, A. 2000. A comparison of voice controlled and mouse controlled web browsing. Proc. of ASSETS’00, 72-79.

[4] CloudGarden, Inc. www.cloudgarden.com, 2008.

[5] Cskszentmihlyi, M. 1990. Flow: The Psychology of Optimal Experience’. New York: Harper and Row. ISBN 0-06-092043-2.

[6] Dai, L., Goldman, R., and Sears, A. 2004. Speech-based Cursor Control: A Study of Grid-based Solutions. ACM Assets ’ 04, October 18-20, 2004.

[7] Feng, J. 2002. Improving Speech-based Navigation during Dictation. CHI 2002, 844- 845.

[8] Feng, J. and Sears, A. 2004. Using Confidence Scores to Improve Hands-free Speech Based Navigation in Continuous Dictation Systems. CHI 2004, 329-356.

[9] Fitts, P.M. 1964. Information Capacity of Discrete Moto Responses. Journal of Exper- imental Psychology, 67, 103-112.

[10] Stategy First, Inc. Galactic Civilizations. www.galciv.com, 2003.

[11] Yo Yo Games, Inc. Game Maker. www.yoyogames.com, 2008.

[12] Gray, J., Shaik, S. et al. SpeechClipse: an Eclipse Speech Plug-in. OOPSLA Workshop on Eclipse Technology Exchange, 2003.

[13] Halverson C., Horn D., Karat C. and Karat J.(1999). The Beauty of Errors: Patterns of Error Correction in Desktop Speech systems. Proceedings of INTERACT’99, 1-9.

[14] Harada, S., Landay, J., Malkin, J., Li, X., and Bilmes, J. 2006. The Vocal Joystick: Evaluation of Voice-based Cursor Control Techniques. Proc. of ASSETS’06, 197-204.

[15] Hauptmann, A. Speech and Gestures for Graphic Image Manipulation. ACM 0-89791- 301-9, 1989.

[16] Igarashi, T., Hughes, J. 2001. Voice as Sound: Using Non-verbal Voice Input for Inter- active Control. ACM UIST’01, 155-156.

[17] Kamel, H. and Landay, J. 1999. The Integrated Communication 2 Draw (IC2D): A Drawing Program for the Visually Impaired. CHI ’99 extended abstracts, 222-223.

[18] Kamel, H. and Landay, J. 2000. A Study of Blind Drawing Practice: Creating Graphical Information without the Visual Channel. Proc. of ASSETS’00, 34-41.

[19] Kamel, H. and Landay, J. 2002. Sketching Images Eyes-free: A Grid-based Dynamic Drawing Tool for the Blind. Proc. of ASSETS’02, 33-40.

[20] Karimullah, A., S., and Sears, A. 2002. Speech-based Cursor Control. Proc. of AS- SETS’02, 178-185.

[21] Manaris, B. and Harkreader, A. 1998. SUITEKeys: A Speech Understanding Interface for the Motor-control Challenged. Proc. of ASSETS’98, 108-115.

[22] Manaris, B., McCauley, R., and MacGybers, V. 2001. An Intelligent Interface for Keyboard and Mouse Control - Providing Full Access to PC Functionality via Speech. Proc. of International Florida AI Research Symposium (FLAIRS’01), 182-188.

[23] MacKenzie, I and Buxton, W. Extending Fitts’ Law to Two-dimensional Tasks. Proc. of CHI’92, 219-226.

[24] Mihara, Y., Shibayama, E, and Takahashi, S. 2005. The Migratory Cursor: Accurate Speech-based Cursor Movement by Moving Multiple Ghost Cursors using Non-Verbal Vocalizations. Proc. of ASSETS’05, 76-83.

[25] Oviatt, S. L. 1997. Multimodal Interactive Maps: Designing for Human Performance. Human-Computer Interaction, 12, 93-129.

[26] Oviatt, S. L. 2000. Taming speech recognition errors within a multimodal interface. Comm. ACM 43,9, 45-51.

[27] Palazzolo, M., Humphrey, C., Nagel, J., and Stolz, A. Adaptation of a Video Game Controller for Use by a Quadriplegic Incorporating Real-time Speech Processing, IEEE 0-7803-7740-0, 2003.

[28] Perakakis, M. and Potamianos, A. 2007. The Effect of Input Mode on Inactivity and Interaction Times of Multimodal Systems. ICMI’07, 102-109.

[29] Sanchanta, M. (2007-09-12). Nintendo’s Wii takes console lead. Financial Times. http://www.ft.com/cms/s/0/51df0c84-6154-11dc-bf25-0000779fd2ac.html. Re- trieved on 2008-01-23.

[30] Sargin, M, et al. Combined Gesture-speech Analysis and Speech Driven Gesture Syn- thesis. Enterface05 Workshop, Belgium, 2005.

[31] Sears A., Karat C-M., Oseitutu K., Karimullah A., Feng J. (2001). Productivity, Sat- isfaction, and Interaction Strategies of Individuals with Spinal Cord Injuries and Tra- ditional Users Interacting with Speech Recognition Software. International Journal of Universal Access in the Information Society, 1(1), 4-15.

[32] Smith, J., and Graham, N. Use of Eye Movements for Video Game Control. ACM ACE 06, June 14-16, 2006.

[33] Sporka, A., Kurniawan, H., Mahmud, M., and Slavik, P. Non-speech Input and Speech Recognition for Real-time Control of Computer Games. Proc. of ASSETS’06, 213-220.

[34] Wang, S et al. Face Tracking as an Augmented Input in Video Games: Enhancing Presence, Role-playing and Control. CHI 2006, April 22-27, 2006.

[35] Zhang, J., Zhao, J., Bai, S., and Huang, Z. Applying Speech Interface to Mahjong Game. Proc. of 10th International Multimedia Modeling Conference (MMM’04), 2004.